{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKuVrdCAj2IWr0b/5jhu3f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushpitab18/PW_MACHINE_LEARNING_ASSIGNMENTS/blob/main/Ensemble_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\"Theoretical : \""
      ],
      "metadata": {
        "id": "w3kcX1G4yZue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Can we use Bagging for regression problems?\n",
        "\n",
        "ans:\n",
        "\n",
        "Yes, Bagging can be used for regression problems. Bagging Regressor is a type of ensemble learning method that combines the predictions of multiple base regressors to improve the overall performance and reduce overfitting.\n",
        "\n",
        "2. What is the difference between multiple model training and single model training?\n",
        "\n",
        "ans :\n",
        "\n",
        "In single model training, a single model is trained on the entire dataset to make predictions. In multiple model training, multiple models are trained on different subsets of the dataset, and their predictions are combined to improve the overall performance. Multiple model training can help reduce overfitting and improve the robustness of the model.\n",
        "\n",
        "3. Explain the concept of feature randomness in Random Forest.\n",
        "\n",
        "ans :\n",
        "\n",
        "In Random Forest, feature randomness refers to the random selection of features at each node of the decision tree. This helps to reduce the correlation between the trees in the forest and improves the overall performance of the model.\n",
        "\n",
        "4. What is OOB (Out-of-Bag) Score?\n",
        "\n",
        "ans :\n",
        "\n",
        "OOB (Out-of-Bag) score is a measure of the performance of a Random Forest model on the samples that are not used in the training of each tree. These samples are called out-of-bag samples. The OOB score is calculated by predicting the out-of-bag samples using each tree and then combining the predictions.\n",
        "\n",
        "5. How can you measure the importance of features in a Random Forest model?\n",
        "\n",
        "ans :\n",
        "\n",
        "Feature importance in a Random Forest model can be measured using the permutation feature importance or the Gini importance. Permutation feature importance is calculated by randomly permuting the values of a feature and measuring the decrease in the model's performance. Gini importance is calculated based on the decrease in impurity (Gini index) caused by a feature.\n",
        "\n",
        "6. Explain the working principle of a Bagging Classifier.\n",
        "\n",
        "\n",
        "ans:\n",
        "\n",
        "A Bagging Classifier works by training multiple instances of a base classifier on different subsets of the training data. The subsets are created using bootstrap sampling, where each sample is selected randomly with replacement. The predictions of each classifier are then combined using voting to produce the final prediction.\n",
        "\n",
        "7. How do you evaluate a Bagging Classifier's performance?\n",
        "\n",
        "\n",
        "ans :\n",
        "\n",
        "A Bagging Classifier's performance can be evaluated using metrics such as accuracy, precision, recall, F1 score, and ROC-AUC score. Cross-validation can be used to estimate the performance of the model on unseen data.\n",
        "\n",
        "8. How does a Bagging Regressor work?\n",
        "\n",
        "\n",
        "ans :\n",
        "\n",
        "A Bagging Regressor works similarly to a Bagging Classifier, but it combines the predictions of multiple base regressors to produce a continuous output. The predictions are typically combined using averaging or weighted averaging.\n",
        "\n",
        "9. What is the main advantage of ensemble techniques?\n",
        "\n",
        "\n",
        "ans :\n",
        "\n",
        "The main advantage of ensemble techniques is that they can improve the performance and robustness of machine learning models by combining the predictions of multiple models. Ensemble techniques can reduce overfitting and improve the accuracy of the model.\n",
        "\n",
        "10. What is the main challenge of ensemble methods?\n",
        "\n",
        "ans :\n",
        "\n",
        "The main challenge of ensemble methods is that they can be computationally expensive and require careful tuning of hyperparameters. Ensemble methods can also be difficult to interpret and explain.\n",
        "\n",
        "11. Explain the key idea behind ensemble techniques.\n",
        "\n",
        "ans :\n",
        "\n",
        "The key idea behind ensemble techniques is to combine the predictions of multiple models to improve the overall performance. Ensemble techniques can be used to reduce overfitting, improve accuracy, and increase robustness.\n",
        "\n",
        "12. What is a Random Forest Classifier?\n",
        "\n",
        "ans :\n",
        "\n",
        "A Random Forest Classifier is a type of ensemble learning method that combines the predictions of multiple decision trees to produce a classification output. Random Forest Classifiers are known for their high accuracy and robustness.\n",
        "\n",
        "13. What are the main types of ensemble techniques?\n",
        "\n",
        "ans :\n",
        "\n",
        "The main types of ensemble techniques are:\n",
        "\n",
        "- Bagging: combines the predictions of multiple models trained on different subsets of the data.\n",
        "- Boosting: combines the predictions of multiple models trained on the residuals of the previous models.\n",
        "- Stacking: combines the predictions of multiple models using a meta-model.\n",
        "\n",
        "14. What is ensemble learning in machine learning?\n",
        "\n",
        "ans :\n",
        "\n",
        "Ensemble learning is a machine learning technique that combines the predictions of multiple models to improve the overall performance. Ensemble learning can be used for classification, regression, and other types of machine learning tasks.\n",
        "\n",
        "15. When should we avoid using ensemble methods?\n",
        "\n",
        "ans :\n",
        "\n",
        "Ensemble methods should be avoided when:\n",
        "\n",
        "- The dataset is small, and the models are prone to overfitting.\n",
        "- The models are highly correlated, and the ensemble does not provide any benefits.\n",
        "- The computational resources are limited, and the ensemble method is too expensive.\n",
        "\n",
        "16. How does Bagging help in reducing overfitting?\n",
        "\n",
        "ans :\n",
        "\n",
        "Bagging helps in reducing overfitting by training multiple models on different subsets of the data. This reduces the impact of noise and outliers in the data and improves the robustness of the model.\n",
        "\n",
        "17. Why is Random Forest better than a single Decision Tree?\n",
        "\n",
        "ans :\n",
        "\n",
        "Random Forest is better than a single Decision Tree for several reasons:\n",
        "\n",
        "1. Reduced Overfitting: Random Forest reduces overfitting by averaging the predictions of multiple trees, which helps to cancel out the noise and variability in individual trees.\n",
        "2. Improved Accuracy: Random Forest often improves the accuracy of predictions by combining the strengths of multiple trees.\n",
        "3. Robustness to Outliers: Random Forest is more robust to outliers and noisy data than a single Decision Tree, as the ensemble effect helps to mitigate the impact of outliers.\n",
        "4. Handling High-Dimensional Data: Random Forest can handle high-dimensional data more effectively than a single Decision Tree, as the random feature selection helps to reduce the impact of irrelevant features.\n",
        "5. Improved Handling of Missing Values: Random Forest can handle missing values more effectively than a single Decision Tree, as the ensemble effect helps to impute missing values.\n",
        "\n",
        "18. What is the role of bootstrap sampling in Bagging?\n",
        "\n",
        "ans :\n",
        "\n",
        "Bootstrap sampling is a key component of Bagging, where each model is trained on a random subset of the training data with replacement. This helps to reduce overfitting and improve the robustness of the model.\n",
        "\n",
        "19. What are some real-world applications of ensemble techniques?\n",
        "\n",
        "ans :\n",
        "\n",
        "Ensemble techniques have many real-world applications, including:\n",
        "\n",
        "- Image classification: Ensemble methods can be used to combine the predictions of multiple models trained on different features or datasets.\n",
        "- Natural language processing: Ensemble methods can be used to combine the predictions of multiple models trained on different linguistic features or datasets.\n",
        "- Financial forecasting: Ensemble methods can be used to combine the predictions of multiple models trained on different economic indicators or datasets.\n",
        "- Medical diagnosis: Ensemble methods can be used to combine the predictions of multiple models trained on different medical features or datasets.\n",
        "\n",
        "20. What is the difference between Bagging and Boosting?\n",
        "\n",
        "ans :\n",
        "\n",
        "Bagging and Boosting are both ensemble techniques, but they differ in how they combine the predictions of multiple models:\n",
        "\n",
        "- Bagging: combines the predictions of multiple models trained on different subsets of the data, where each model is trained independently.\n",
        "- Boosting: combines the predictions of multiple models trained on the residuals of the previous models, where each model is trained to correct the errors of the previous model.\n",
        "\n",
        "In Bagging, each model is trained independently, and the predictions are combined using voting or averaging. In Boosting, each model is trained to correct the errors of the previous model, and the predictions are combined using weighted voting or averaging.\n",
        "\n",
        "Boosting is typically more sensitive to outliers and noisy data than Bagging, but it can also be more effective in certain situations. Bagging is often used to reduce overfitting and improve the robustness of a model, while Boosting is often used to improve the accuracy of a model.\n",
        "\n",
        "Here's a summary of the key differences between Bagging and Boosting:\n",
        "\n",
        "|  | Bagging | Boosting |\n",
        "| --- | --- | --- |\n",
        "| Training | Each model is trained independently on a random subset of the data | Each model is trained to correct the errors of the previous model |\n",
        "| Prediction | Predictions are combined using voting or averaging | Predictions are combined using weighted voting or averaging |\n",
        "| Effectiveness | Can reduce overfitting and improve robustness | Can improve accuracy, but may be sensitive to outliers and noisy data |\n",
        "| Use case | Suitable for reducing overfitting and improving robustness | Suitable for improving accuracy, especially in situations where the data is complex or has many features |\n",
        "\n",
        "In summary, Bagging and Boosting are both powerful ensemble techniques that can be used to improve the performance of machine learning models. The choice between Bagging and Boosting depends on the specific problem and dataset, as well as the goals of the project."
      ],
      "metadata": {
        "id": "IUjEzZ8Ww7L3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\" Practical : \""
      ],
      "metadata": {
        "id": "iF7kLgX3ya8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy."
      ],
      "metadata": {
        "id": "qprLUMexy12s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans:\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Bagging Classifier using Decision Trees\n",
        "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set and print accuracy\n",
        "y_pred = bagging_clf.predict(X_test)\n",
        "print(\"Bagging Classifier Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QSH3Mkp2667",
        "outputId": "caf51c47-7de1-4912-bed3-9b8cb1a643b7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)."
      ],
      "metadata": {
        "id": "YaTy5XYU2_S-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a regression dataset\n",
        "X, y = make_regression(n_samples=100, n_features=5, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Bagging Regressor using Decision Trees\n",
        "bagging_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10, random_state=42)\n",
        "bagging_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set and print MSE\n",
        "y_pred = bagging_reg.predict(X_test)\n",
        "print(\"Bagging Regressor MSE:\", mean_squared_error(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y8YP3FQ3EAu",
        "outputId": "4ff67b70-7dc7-4cdf-ce95-c4d1f3532f6d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor MSE: 6126.9021847713475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores."
      ],
      "metadata": {
        "id": "-1tH2WsP3VEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Load the breast cancer dataset\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importance scores\n",
        "print(\"Feature Importance Scores:\")\n",
        "for feature, importance in zip(cancer.feature_names, rf_clf.feature_importances_):\n",
        "    print(f\"{feature}: {importance:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDR4jRhB3WVq",
        "outputId": "23812f42-658c-4e18-cf35-4b4298cb379f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Scores:\n",
            "mean radius: 0.05\n",
            "mean texture: 0.01\n",
            "mean perimeter: 0.05\n",
            "mean area: 0.05\n",
            "mean smoothness: 0.01\n",
            "mean compactness: 0.01\n",
            "mean concavity: 0.07\n",
            "mean concave points: 0.11\n",
            "mean symmetry: 0.00\n",
            "mean fractal dimension: 0.00\n",
            "radius error: 0.02\n",
            "texture error: 0.00\n",
            "perimeter error: 0.01\n",
            "area error: 0.02\n",
            "smoothness error: 0.00\n",
            "compactness error: 0.01\n",
            "concavity error: 0.01\n",
            "concave points error: 0.00\n",
            "symmetry error: 0.00\n",
            "fractal dimension error: 0.01\n",
            "worst radius: 0.08\n",
            "worst texture: 0.02\n",
            "worst perimeter: 0.07\n",
            "worst area: 0.15\n",
            "worst smoothness: 0.01\n",
            "worst compactness: 0.02\n",
            "worst concavity: 0.03\n",
            "worst concave points: 0.14\n",
            "worst symmetry: 0.01\n",
            "worst fractal dimension: 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Train a Random Forest Regressor and compare its performance with a single Decision Tree."
      ],
      "metadata": {
        "id": "yp1haUkv4ehK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate a regression dataset\n",
        "X, y = make_regression(n_samples=100, n_features=5, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "# Train a single Decision Tree Regressor\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "dt_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set and compare MSE\n",
        "y_pred_rf = rf_reg.predict(X_test)\n",
        "y_pred_dt = dt_reg.predict(X_test)\n",
        "print(\"Random Forest Regressor MSE:\", mean_squared_error(y_test, y_pred_rf))\n",
        "print(\"Decision Tree Regressor MSE:\", mean_squared_error(y_test, y_pred_dt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-LqFSDg6Jr1",
        "outputId": "0d8378c9-0879-4dbf-aa1c-704dd57684c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor MSE: 5972.68134439264\n",
            "Decision Tree Regressor MSE: 19364.814027200642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier.\n"
      ],
      "metadata": {
        "id": "vzMlZdaU6P8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "#ans :\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Classifier with OOB score\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Print the OOB score\n",
        "print(\"Out-of-Bag Score:\", rf_clf.oob_score_)\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Print the OOB score\n",
        "print(\"Out-of-Bag Score:\", rf_clf.oob_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2p0g-qP6ZkQ",
        "outputId": "15d9b27f-5420-4a02-9ddd-8b83902769fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out-of-Bag Score: 0.9166666666666666\n",
            "Out-of-Bag Score: 0.9166666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. Train a Bagging Classifier using SVM as a base estimator and print accuracy."
      ],
      "metadata": {
        "id": "FPrgwmoy736C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Bagging Classifier using SVM\n",
        "bagging_svm = BaggingClassifier(estimator=SVC(), n_estimators=10, random_state=42)\n",
        "bagging_svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set and print accuracy\n",
        "y_pred = bagging_svm.predict(X_test)\n",
        "print(\"Bagging SVM Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYjZCtYb8Lfc",
        "outputId": "c3fae419-edbd-4231-d06d-47ad5d637aa5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging SVM Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Train a Random Forest Classifier with different numbers of trees and compare accuracy."
      ],
      "metadata": {
        "id": "1Mlxq81Y8QYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifiers with different numbers of trees\n",
        "for n_estimators in [10, 50, 100, 200]:\n",
        "    rf_clf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
        "    rf_clf.fit(X_train, y_train)\n",
        "    y_pred = rf_clf.predict(X_test)\n",
        "    print(f\"Random Forest Accuracy with {n_estimators} trees:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRX8Zk6h8Vp_",
        "outputId": "9281fe22-0d8a-4092-8f08-d6b51c778e68"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy with 10 trees: 1.0\n",
            "Random Forest Accuracy with 50 trees: 1.0\n",
            "Random Forest Accuracy with 100 trees: 1.0\n",
            "Random Forest Accuracy with 200 trees: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score."
      ],
      "metadata": {
        "id": "nrG_nw-U8jVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Bagging Classifier using Logistic Regression\n",
        "bagging_lr = BaggingClassifier(estimator=LogisticRegression(), n_estimators=10, random_state=42)\n",
        "bagging_lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set and print AUC score\n",
        "y_pred_proba = bagging_lr.predict_proba(X_test)[:, 1]\n",
        "print(\"Bagging Logistic Regression AUC Score:\", roc_auc_score(y_test, y_pred_proba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YD-5ZAS9riK",
        "outputId": "d3f9dacb-dfdd-45c3-e2c8-d32f2edc9cfb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Logistic Regression AUC Score: 0.99737962659679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. Train a Random Forest Regressor and analyze feature importance scores."
      ],
      "metadata": {
        "id": "ZUZoQI_t96Ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a regression dataset\n",
        "X, y = make_regression(n_samples=100, n_features=5, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importance scores\n",
        "print(\"Feature Importance Scores:\")\n",
        "for i, importance in enumerate(rf_reg.feature_importances_):\n",
        "    print(f\"Feature {i+1}: {importance:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jaz0dd_9_gX",
        "outputId": "6c221ab5-6188-41e8-99ef-e08f5fcb79c6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Scores:\n",
            "Feature 1: 0.09\n",
            "Feature 2: 0.53\n",
            "Feature 3: 0.18\n",
            "Feature 4: 0.12\n",
            "Feature 5: 0.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n"
      ],
      "metadata": {
        "id": "-Zydo9SS-D-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Bagging Classifier\n",
        "bagging_clf = BaggingClassifier(n_estimators=10, random_state=42)\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_clf.predict(X_test)\n",
        "print(\"Bagging Accuracy:\", accuracy_score(y_test, y_pred_bagging))\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbKnygI1-PqC",
        "outputId": "938bfa30-98f7-44a3-d7f5-981e328e8510"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Accuracy: 1.0\n",
            "Random Forest Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV\n"
      ],
      "metadata": {
        "id": "NLmq9iTd-XwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Perform grid search\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(rf_clf, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2_51fM9AFXj",
        "outputId": "518e65be-b4b1-4226-9eaf-7cd73ba7a147"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 10}\n",
            "Best Score: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "32. Train a Bagging Regressor with different numbers of base estimators and compare performance\n"
      ],
      "metadata": {
        "id": "z2-D5CBVAmkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate a regression dataset\n",
        "X, y = make_regression(n_samples=100, n_features=5, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Bagging Regressors with different numbers of base estimators\n",
        "for n_estimators in [10, 50, 100, 200]:\n",
        "\n",
        "    bagging_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=n_estimators, random_state=42)\n",
        "    bagging_reg.fit(X_train, y_train)\n",
        "    y_pred = bagging_reg.predict(X_test)\n",
        "    print(f\"Bagging Regressor MSE with {n_estimators} estimators:\", mean_squared_error(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrlf8hz2Arca",
        "outputId": "62221a8a-9f21-49fc-ae50-f31a5e395aa9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor MSE with 10 estimators: 6126.9021847713475\n",
            "Bagging Regressor MSE with 50 estimators: 6256.303614093673\n",
            "Bagging Regressor MSE with 100 estimators: 5959.709942142359\n",
            "Bagging Regressor MSE with 200 estimators: 5961.95737726446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "33. Train a Random Forest Classifier and analyze misclassified samples\n"
      ],
      "metadata": {
        "id": "KSythgv9A_Bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Analyze misclassified samples\n",
        "misclassified_samples = X_test[y_test != y_pred]\n",
        "print(\"Misclassified Samples:\")\n",
        "print(misclassified_samples)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7ptJDFmBDHO",
        "outputId": "8ec92d74-f71e-4806-ee28-f32a16d68460"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Misclassified Samples:\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier\n"
      ],
      "metadata": {
        "id": "BgpOHY-kBHsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Bagging Classifier\n",
        "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_clf.predict(X_test)\n",
        "\n",
        "# Train a single Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "\n",
        "# Compare performance\n",
        "print(\"Bagging Accuracy:\", accuracy_score(y_test, y_pred_bagging))\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV5N74PABYnc",
        "outputId": "c521cbaf-e950-413b-cddb-72e717e70ddb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Accuracy: 1.0\n",
            "Decision Tree Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "35. Train a Random Forest Classifier and visualize the confusion matrix\n"
      ],
      "metadata": {
        "id": "AkapI7eCBq3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Create a confusion matrix\n",
        "conf_mat = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_mat, annot=True, cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Create a confusion matrix\n",
        "conf_mat = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_mat, annot=True, cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fE0va_mOBvM-",
        "outputId": "295379ff-87ab-4df4-9dd6-08ee4ca1ce0c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy\n"
      ],
      "metadata": {
        "id": "dr4wQsk0CGAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the base estimators\n",
        "base_estimators = [\n",
        "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
        "    ('svm', SVC(probability=True, random_state=42)),\n",
        "    ('lr', LogisticRegression(random_state=42))\n",
        "]\n",
        "\n",
        "# Train a Stacking Classifier\n",
        "stacking_clf = StackingClassifier(estimators=base_estimators, final_estimator=LogisticRegression(random_state=42))\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "y_pred = stacking_clf.predict(X_test)\n",
        "\n",
        "# Print accuracy\n",
        "print(\"Stacking Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLhqDd_CCNO6",
        "outputId": "c692d575-3c47-4120-ede1-af539b1b8de2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "37. Train a Random Forest Classifier and print the top 5 most important features\n"
      ],
      "metadata": {
        "id": "ny5YaLNdCUKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Print the top 5 most important features\n",
        "feature_importances = rf_clf.feature_importances_\n",
        "top_5_features = sorted(zip(feature_importances, iris.feature_names), reverse=True)[:5]\n",
        "print(\"Top 5 Most Important Features:\")\n",
        "for importance, feature in top_5_features:\n",
        "    print(f\"{feature}: {importance:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie8yMiKICYxZ",
        "outputId": "c91f4ac8-d277-44d6-dd89-1b27bf11096f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Most Important Features:\n",
            "petal length (cm): 0.44\n",
            "petal width (cm): 0.42\n",
            "sepal length (cm): 0.11\n",
            "sepal width (cm): 0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score\n"
      ],
      "metadata": {
        "id": "_CfqRMySCfEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Bagging Classifier\n",
        "# Changed 'base_estimator' to 'estimator'\n",
        "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "y_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJMXEspnCtPu",
        "outputId": "f3b11674-27e8-4225-b32a-e3f5592030d8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy\n"
      ],
      "metadata": {
        "id": "5JnSLqZJCv1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifiers with different max_depth values\n",
        "for max_depth in [None, 5, 10, 15]:\n",
        "    rf_clf = RandomForestClassifier(n_estimators=100, max_depth=max_depth, random_state=42)\n",
        "    rf_clf.fit(X_train, y_train)\n",
        "    y_pred = rf_clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Max Depth: {max_depth}, Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1dPec7sC1Ri",
        "outputId": "266f0da7-0f14-45be-f9df-77d2fb08aef8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Depth: None, Accuracy: 1.00\n",
            "Max Depth: 5, Accuracy: 1.00\n",
            "Max Depth: 10, Accuracy: 1.00\n",
            "Max Depth: 15, Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance\n"
      ],
      "metadata": {
        "id": "9rBhIpodC55B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate a regression dataset\n",
        "X, y = make_regression(n_samples=100, n_features=5, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Bagging Regressors with different base estimators\n",
        "for base_estimator in [DecisionTreeRegressor(), KNeighborsRegressor()]:\n",
        "    bagging_reg = BaggingRegressor(estimator=base_estimator, n_estimators=10, random_state=42)\n",
        "    bagging_reg.fit(X_train, y_train)\n",
        "    y_pred = bagging_reg.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Base Estimator: {type(base_estimator).__name__}, MSE: {mse:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p70X9dkSDN_N",
        "outputId": "984d4730-5306-43ed-efaa-08ab7b857278"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base Estimator: DecisionTreeRegressor, MSE: 6126.90\n",
            "Base Estimator: KNeighborsRegressor, MSE: 3898.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score\n"
      ],
      "metadata": {
        "id": "sq90K4lrDS7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate performance using ROC-AUC Score\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke0Aqrv_DXRj",
        "outputId": "2f0d7032-0216-4be4-950d-f20820389fec"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9952505732066819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "42. Train a Bagging Classifier and evaluate its performance using cross-validation\n"
      ],
      "metadata": {
        "id": "VU9PL1p4Dbo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Train a Bagging Classifier\n",
        "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "\n",
        "# Evaluate performance using cross-validation\n",
        "scores = cross_val_score(bagging_clf, X, y, cv=5)\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Average Cross-Validation Score:\", scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HpLbeIGDfsT",
        "outputId": "05e10da1-dc82-4a60-cec3-e59892137cc5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.96666667 0.96666667 0.9        0.93333333 1.        ]\n",
            "Average Cross-Validation Score: 0.9533333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "43. Train a Random Forest Classifier and plot the Precision-Recall curve\n"
      ],
      "metadata": {
        "id": "xhKC9dv_DsnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Plot the Precision-Recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "SjfzZ_-xDxaq",
        "outputId": "696dbaf9-9a1c-46ca-d356-c150ab611ce7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy\n"
      ],
      "metadata": {
        "id": "uE7sybO1D2F7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the base estimators\n",
        "base_estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('lr', LogisticRegression(random_state=42))\n",
        "]\n",
        "\n",
        "# Train a Stacking Classifier\n",
        "stacking_clf = StackingClassifier(estimators=base_estimators, final_estimator=LogisticRegression(random_state=42))\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "y_pred = stacking_clf.predict(X_test)\n",
        "\n",
        "# Compare accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Stacking Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAPVkUv9D7L5",
        "outputId": "ad19d3c9-2998-477f-fd5d-56dafca8803b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance\n"
      ],
      "metadata": {
        "id": "VaWbwuRiECVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ans :\n",
        "\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate a regression dataset\n",
        "X, y = make_regression(n_samples=100, n_features=5, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Bagging Regressors with different levels of bootstrap samples\n",
        "for max_samples in [0.5, 0.8, 1.0]:\n",
        "    bagging_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10, max_samples=max_samples, random_state=42)\n",
        "    bagging_reg.fit(X_train, y_train)\n",
        "    y_pred = bagging_reg.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Max Samples: {max_samples}, MSE: {mse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X36k0K9EEHS7",
        "outputId": "6c4521b9-f7b7-4c3b-dc74-91885a406e91"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Samples: 0.5, MSE: 7023.84\n",
            "Max Samples: 0.8, MSE: 9035.75\n",
            "Max Samples: 1.0, MSE: 6126.90\n"
          ]
        }
      ]
    }
  ]
}