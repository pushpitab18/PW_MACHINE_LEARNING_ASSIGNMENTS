{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdexiodZE+AHiLD7W/OmeH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushpitab18/PW_MACHINE_LEARNING_ASSIGNMENTS/blob/main/Feature_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\"FEATURE ENGINEERING :  \"\n",
        "\n",
        "#Assignment Questions :   \n",
        "\n",
        "\n",
        "###Q1 :  What is a parameter?\n",
        "\n",
        "\n",
        "####ans :  \n",
        "\n",
        "In programming, a parameter is a variable that is passed to a function, method, or procedure when it is called. Parameters are used to provide input values to a function, allowing it to perform its intended task.\n",
        "\n",
        "####Here are some key characteristics of parameters:\n",
        "\n",
        "1. Input values: Parameters are used to pass input values to a function.\n",
        "2. Variable: Parameters are variables that can hold different values each time the function is called.\n",
        "3. Passed by value or reference: Parameters can be passed by value (a copy of the value is passed) or by reference (a reference to the original value is passed).\n",
        "4. Defined in the function signature: Parameters are defined in the function signature, which specifies the function's name, return type, and parameter list.\n",
        "\n"
      ],
      "metadata": {
        "id": "VuBXfaSxprLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q2 : What is correlation? What does negative correlation mean?\n",
        "\n",
        "\n",
        "####ans :\n",
        "\n",
        "Correlation refers to the statistical relationship between two or more continuous variables. It measures how closely the variables move together, either in the same direction (positive correlation) or in opposite directions (negative correlation).\n",
        "\n",
        "####Types of Correlation :\n",
        "\n",
        "Positive Correlation : When two variables move in the same direction, it's called a positive correlation. As one variable increases, the other variable also tends to increase.\n",
        "\n",
        "Negative Correlation : When two variables move in opposite directions, it's called a negative correlation. As one variable increases, the other variable tends to decrease.\n",
        "\n",
        "####Interpretation of Correlation Coefficient -\n",
        "\n",
        "The correlation coefficient (often denoted as ρ) ranges from -1 to 1.\n",
        "\n",
        "- ρ = 1: Perfect positive correlation\n",
        "- ρ = -1: Perfect negative correlation\n",
        "- ρ = 0: No correlation\n",
        "\n",
        "####Importance of Correlation :\n",
        "\n",
        "Correlation analysis is essential in feature engineering because it helps:\n",
        "\n",
        "1. Identify redundant features: Highly correlated features can be redundant, and removing one of them can simplify the model without losing much information.\n",
        "2. Select relevant features: Correlation analysis can help identify features that are strongly correlated with the target variable, making them more likely to be relevant for the model.\n",
        "3. Detect multicollinearity: Correlation analysis can detect multicollinearity, which occurs when two or more features are highly correlated with each other. This can cause issues with model interpretability and stability."
      ],
      "metadata": {
        "id": "SgUbgKP1xwSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q3 : Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "\n",
        "####ans :\n",
        "\n",
        "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that involves training algorithms to learn from data and make predictions, decisions, or recommendations without being explicitly programmed.\n",
        "\n",
        "The main components of Machine Learning are:\n",
        "\n",
        "1. Data: The dataset used to train and test the ML model.\n",
        "2. Model: The algorithm or mathematical representation of the relationship between the input data and the predicted output.\n",
        "3. Algorithm: The specific technique or method used to train the model, such as decision trees, neural networks, or clustering.\n",
        "4. Features: The individual characteristics or attributes of the data that are used to train the model.\n",
        "5. Target Variable: The output or response variable that the model is trying to predict or classify.\n",
        "6. Training: The process of teaching the model to learn from the data.\n",
        "7. Testing: The process of evaluating the performance of the trained model on unseen data.\n",
        "\n",
        "These components work together to enable Machine Learning models to learn from data, make predictions, and improve their performance over time."
      ],
      "metadata": {
        "id": "ranQTqWv-7l9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q4 : How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "\n",
        "####ans :    \n",
        "The loss value, also known as the cost function or objective function, is a measure of the difference between the model's predictions and the actual true values. It helps determine whether a model is good or not in several ways:\n",
        "\n",
        "1. Lower loss value indicates better fit: A lower loss value means the model's predictions are closer to the actual values, indicating a better fit.\n",
        "2. Convergence: If the loss value decreases and converges to a minimum value during training, it suggests the model is learning and improving.\n",
        "3. Overfitting/Underfitting detection: If the loss value on the training set is significantly lower than on the validation/test set, it may indicate overfitting. Conversely, if the loss value is high on both sets, it may indicate underfitting.\n",
        "4. Model comparison: Loss values can be used to compare the performance of different models or hyperparameters, helping us to choose the best one.\n",
        "\n",
        "Common loss functions include Mean Squared Error (MSE), Mean Absolute Error (MAE), Cross-Entropy Loss, and more. The choice of loss function depends on the specific problem and model architecture."
      ],
      "metadata": {
        "id": "u4aVm5MTNtyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q5 : What are continuous and categorical variables?\n",
        "\n",
        "\n",
        "####ans :  \n",
        "\n",
        "In statistics and data analysis, variables can be classified into two main categories: continuous and categorical.\n",
        "\n",
        "####Continuous Variables :\n",
        "\n",
        "Continuous variables are numerical variables that can take any value within a given range or interval, including fractions and decimals. They can be measured to any level of precision.\n",
        "\n",
        "####Examples:\n",
        "\n",
        "- Height (e.g., 175.2 cm)\n",
        "- Weight (e.g., 65.5 kg)\n",
        "- Temperature (e.g., 23.7°C)\n",
        "\n",
        "####Categorical Variables :\n",
        "\n",
        "Categorical variables, also known as discrete variables, are variables that take on distinct, non-numerical values. They represent categories or groups.\n",
        "\n",
        "####Examples:\n",
        "\n",
        "- Color (e.g., red, blue, green)\n",
        "- Gender (e.g., male, female)\n",
        "- Nationality (e.g., American, Canadian, Indian)\n",
        "\n",
        "####categorical variables can be further divided into:\n",
        "\n",
        "- Nominal variables: No inherent order (e.g., color, nationality)\n",
        "- Ordinal variables: Have a natural order (e.g., education level: high school, bachelor's, master's)"
      ],
      "metadata": {
        "id": "-pWjxgOUUipw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q6 : How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "\n",
        "####ans :  \n",
        "\n",
        "Handling categorical variables is crucial in Machine Learning, as many algorithms can't directly process categorical data. Here are common techniques to handle categorical variables:\n",
        "\n",
        "1. Label Encoding -\n",
        "\n",
        "Assign a unique integer value to each category. This is simple but can lead to ordinality issues.\n",
        "\n",
        "2. One-Hot Encoding (OHE) -\n",
        "\n",
        "Create new binary features for each category. This is a popular method but can lead to the curse of dimensionality.\n",
        "\n",
        "3. Binary Encoding -\n",
        "\n",
        "Similar to OHE, but uses binary digits to represent categories.\n",
        "\n",
        "4. Hashing -\n",
        "\n",
        "Use a hash function to map categories to numerical values.\n",
        "\n",
        "5. Ordinal Encoding -\n",
        "\n",
        "Assign integer values to categories based on their natural order.\n",
        "\n",
        "6. 'Pandas' get_dummies() function -\n",
        "\n",
        "A convenient way to perform OHE in Python.\n",
        "\n",
        "7. Category Embeddings -\n",
        "\n",
        "Learn dense vector representations for categories using neural networks.\n",
        "\n",
        "8. Target Encoding -\n",
        "\n",
        "Replace each category with a weighted average of the target variable.\n",
        "\n",
        "####When choosing a technique, consider:\n",
        "\n",
        "- The number of categories\n",
        "- The type of machine learning algorithm\n",
        "- The presence of ordinality\n",
        "- The risk of overfitting\n"
      ],
      "metadata": {
        "id": "GMHC-z-RWJ35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q7 : What do you mean by training and testing a dataset?\n",
        "\n",
        "\n",
        "####ans :\n",
        "\n",
        "In machine learning, a dataset is typically split into two parts: a training set and a testing set.\n",
        "\n",
        "Training Set -\n",
        "\n",
        "- The training set is used to train the machine learning model.\n",
        "- The model learns patterns and relationships in the data by iterating through the training set.\n",
        "- The goal is to optimize the model's parameters to make accurate predictions.\n",
        "\n",
        "Testing Set -\n",
        "\n",
        "- The testing set, also known as the validation set or holdout set, is used to evaluate the trained model's performance.\n",
        "- The model is tested on unseen data to estimate its ability to generalize and make predictions on new, unknown data.\n",
        "- The testing set provides an unbiased evaluation of the model's performance.\n"
      ],
      "metadata": {
        "id": "j_vddqVpi5Ux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q8 : What is sklearn.preprocessing?\n",
        "\n",
        "\n",
        "####ans :   \n",
        "\n",
        "sklearn.preprocessing is a module in the popular Python machine learning library scikit-learn. It provides various functions and classes for preprocessing data, which is an essential step in the machine learning pipeline.\n",
        "\n",
        "####The sklearn.preprocessing module offers several preprocessing techniques, including:\n",
        "\n",
        "1. Scaling:\n",
        "\n",
        " Scaling methods, such as StandardScaler and MinMaxScaler, transform numerical features to have similar magnitudes, which can improve model performance.\n",
        "\n",
        "2. Normalization:\n",
        "\n",
        " Normalization methods, such as Normalizer, transform numerical features to have similar scales, which can improve model performance.\n",
        "\n",
        "3. Encoding:\n",
        "\n",
        " Encoding methods, such as OneHotEncoder and LabelEncoder, transform categorical features into numerical representations that can be processed by machine learning algorithms.\n",
        "\n",
        "4. Transformation:\n",
        "\n",
        " Transformation methods, such as PolynomialFeatures and Logistic, transform features to create new features that can improve model performance.\n"
      ],
      "metadata": {
        "id": "85JenrvRkCFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q9 : What is a Test set?\n",
        "\n",
        "####ans :\n",
        "\n",
        "In machine learning, a test set (also known as a validation set or holdout set) is a portion of the dataset that is used to evaluate the performance of a trained model.\n",
        "\n",
        "The test set is typically a separate subset of data that is not used during the training process. Instead, it's used to assess the model's ability to generalize and make predictions on unseen data.\n",
        "\n",
        "####The test set serves several purposes:\n",
        "\n",
        "1. Evaluates model performance:\n",
        "\n",
        " The test set provides an unbiased estimate of the model's performance on new, unseen data.\n",
        "\n",
        "2. Prevents overfitting:\n",
        "\n",
        " By evaluating the model on a separate test set, you can detect overfitting, where the model is too specialized to the training data.\n",
        "\n",
        "3. Hyperparameter tuning:\n",
        "\n",
        " The test set can be used to evaluate the model's performance with different hyperparameters, helping you find the optimal configuration.\n",
        "\n",
        "4. Model selection:\n",
        "\n",
        " The test set can be used to compare the performance of different models and select the best one.\n",
        "\n",
        "-The test set is usually used as a final evaluation of the model's performance after hyperparameter tuning and model selection have been completed."
      ],
      "metadata": {
        "id": "y9LyuvTHkqkg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q10 : How do we split data for model fitting (training and testing) in Python?How do you approach a Machine Learning problem ?\n",
        "\n",
        "\n",
        "####ans :\n",
        "\n",
        "To split data for model fitting in Python, you can use the train_test_split function from the sklearn.model_selection module:\n"
      ],
      "metadata": {
        "id": "mqVMd-zfmRyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "#sample data for demonstration\n",
        "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])  # Feature matrix\n",
        "y = np.array([0, 1, 0, 1])  # Target variable\n",
        "\n",
        "#split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "yfnMxcuPnnEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Here's a step-by-step approach to tackling a machine learning problem:\n",
        "\n",
        "1. Problem Formulation:\n",
        "    \n",
        "    - Define the problem and identify the goals\n",
        "    - Determine the type of machine learning problem (classification, regression, clustering, etc.)\n",
        "\n",
        "2. Data Collection:\n",
        "\n",
        "    - Gather relevant data from various sources\n",
        "    - Ensure data quality and handle missing values\n",
        "3. Data Preprocessing:\n",
        "    - Clean and preprocess the data\n",
        "    - Normalize or scale the data if necessary\n",
        "    - Handle categorical variables\n",
        "4. Exploratory Data Analysis (EDA):\n",
        "    - Visualize the data to understand distributions and relationships\n",
        "    - Identify potential issues or biases\n",
        "5. Feature Engineering:\n",
        "    - Select relevant features and transform them if necessary\n",
        "    - Create new features to improve model performance\n",
        "6. Model Selection:\n",
        "    - Choose a suitable machine learning algorithm\n",
        "    - Consider the type of problem, data characteristics, and computational resources\n",
        "7. Model Training and Evaluation:\n",
        "    - Split the data into training and testing sets\n",
        "    - Train the model on the training data\n",
        "    - Evaluate the model on the testing data using metrics such as accuracy, precision, recall, F1 score, etc.\n",
        "8. Model Tuning and Hyperparameter Optimization:\n",
        "    - Adjust hyperparameters to improve model performance\n",
        "    - Use techniques such as grid search, random search, or Bayesian optimization\n",
        "9. Model Deployment and Maintenance:\n",
        "    - Deploy the trained model in a production-ready environment\n",
        "    - Monitor the model's performance and retrain as necessary\n"
      ],
      "metadata": {
        "id": "orxDsTg2oqDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q11 : Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "\n",
        "####ans :   \n",
        "\n",
        "Performing Exploratory Data Analysis (EDA) before fitting a model is a critical step in the data analysis pipeline. Here are the key reasons why it is necessary:\n",
        "\n",
        "1. Understand the Data :\n",
        "   - Data Structure : EDA helps you understand the structure of the dataset, including its dimensions, data types, and organization.\n",
        "   - Identify Variables : It allows you to familiarize yourself with the features and target variables, their relationships, and the context of the data.\n",
        "\n",
        "2. Detect Data Issues\n",
        "   - Missing Values : Identify missing data and decide on strategies to handle it (e.g., imputation, removal).\n",
        "   - Outliers : Detect outliers that could skew the results and determine how to manage them.\n",
        "   - Erroneous Values : Spot incorrect or inconsistent values that may need correction.\n",
        "\n",
        "3. Understand Distributions\n",
        "   - EDA allows you to visualize the distributions of variables, helping you to understand their ranges, central tendencies, and variability. This is particularly useful for feature scaling and normalization.\n",
        "\n",
        "4.  Feature Relationships\n",
        "   - Correlations : Analyze correlations between features and the target variable to identify relevant predictors.\n",
        "   - Feature Interactions:  Spot patterns or interactions that might improve the model's predictive performance.\n",
        "\n",
        "5. Guide Feature Engineering\n",
        "   - Insights from EDA can guide the creation of new features or transformations to improve model performance.\n",
        "\n",
        "6. Choose the Right Model\n",
        "   - EDA helps identify the nature of the problem (e.g., regression, classification, clustering) and guides the selection of an appropriate model.\n",
        "\n",
        "7. Prevent Overfitting or Misleading Results\n",
        "   - Understanding the data prevents fitting a model blindly, which could lead to overfitting, underfitting, or misleading interpretations.\n",
        "\n",
        "8. Improve Model Interpretability\n",
        "   - By understanding the data, you can better interpret model outputs and communicate findings effectively.\n",
        "\n",
        "9. Validate Assumptions\n",
        "   - Some models have assumptions (e.g., linearity, normality, homoscedasticity) that can be checked during EDA to ensure the model is suitable for the data.\n",
        "\n",
        "10. Save Time\n",
        "   - Addressing data quality and feature relevance upfront saves time during model tuning and evaluation, reducing the risk of rework.\n",
        "\n",
        "In short, EDA helps to ensure the quality of the dataset, improves the effectiveness of the model, and increases confidence in the results. Skipping EDA may lead to suboptimal models and unreliable conclusions."
      ],
      "metadata": {
        "id": "RZLZndUhrXG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q12 : What is correlation?\n",
        "\n",
        "\n",
        "####ans :  \n",
        "\n",
        "Correlation is a statistical measure that describes the relationship between two continuous variables. It measures how closely the variables move together, either in the same direction (positive correlation) or in opposite directions (negative correlation).\n",
        "\n",
        "####Types of Correlation :\n",
        "\n",
        "1. Positive Correlation: When two variables move in the same direction, it's called a positive correlation. As one variable increases, the other variable also tends to increase.\n",
        "2. Negative Correlation: When two variables move in opposite directions, it's called a negative correlation. As one variable increases, the other variable tends to decrease.\n",
        "3. No Correlation: When two variables don't have a significant relationship, it's called no correlation or zero correlation.\n",
        "\n",
        "\n",
        "In summary, correlation is a statistical measure that describes the relationship between two continuous variables. It's essential to understand the types of correlation, correlation coefficient, and interpretation to make informed decisions in data analysis and machine learning."
      ],
      "metadata": {
        "id": "V6OIzLMpt9h_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q13 : What does negative correlation mean?\n",
        "\n",
        "####ans :   \n",
        "\n",
        "Negative correlation means that as one variable increases, the other variable tends to decrease. In other words, the two variables move in opposite directions.\n",
        "\n",
        "####For example:\n",
        "\n",
        "- As the amount of rainfall increases, the number of people visiting the beach tends to decrease.\n",
        "- As the price of a product increases, the demand for that product tends to decrease.\n",
        "\n",
        "####In both cases, there is a negative correlation between the two variables.\n",
        "\n",
        "Characteristics of Negative Correlation :\n",
        "\n",
        "- As one variable increases, the other variable decreases.\n",
        "- The correlation coefficient (r) is negative, typically between -1 and 0.\n",
        "- The scatterplot of the two variables would show a downward trend.\n",
        "\n",
        "Examples of Negative Correlation :\n",
        "\n",
        "- The relationship between temperature and heating costs: as temperature increases, heating costs decrease.\n",
        "- The relationship between exercise and body fat percentage: as exercise increases, body fat percentage decreases.\n",
        "- The relationship between study time and exam anxiety: as study time increases, exam anxiety decreases.\n",
        "\n",
        "correlation does not imply causation. Just because two variables are negatively correlated, it doesn't mean that one causes the other."
      ],
      "metadata": {
        "id": "zK2owsunu-P0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q14 : How can you find correlation between variables in Python?\n",
        "\n",
        "\n",
        "####ans :\n",
        "\n",
        " we can find the correlation between variables in Python using the corr() function from the pandas library or the corrcoef() function from the NumPy library.\n",
        "\n"
      ],
      "metadata": {
        "id": "RHgvQ4o7wxZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Method 1: Using pandas\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# create a DataFrame\n",
        "data = {'A': [1, 2, 3, 4, 5],\n",
        "        'B': [2, 3, 5, 7, 11]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# calculate the correlation between columns\n",
        "correlation = df.corr()\n",
        "\n",
        "print(correlation)\n",
        "\n",
        "\n",
        "#This will output the correlation matrix, showing the correlation between each pair of columns.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWyBeoR7xRFH",
        "outputId": "a03a2f6c-2918-4aa5-82d8-ab38b7a3963d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          A         B\n",
            "A  1.000000  0.972272\n",
            "B  0.972272  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Method 2: Using NumPy\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# create two arrays\n",
        "A = np.array([1, 2, 3, 4, 5])\n",
        "B = np.array([2, 3, 5, 7, 11])\n",
        "\n",
        "# calculate the correlation coefficient\n",
        "correlation_coefficient = np.corrcoef(A, B)[0, 1]\n",
        "\n",
        "print(correlation_coefficient)\n",
        "\n",
        "\n",
        "#This will output the correlation coefficient between the two arrays.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2-K0kOixbJK",
        "outputId": "60b18d97-7294-40e4-8789-716921c911c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9722718241315028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Method 3: Using seaborn\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# create a DataFrame\n",
        "data = {'A': [1, 2, 3, 4, 5],\n",
        "        'B': [2, 3, 5, 7, 11]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# create a scatterplot with regression line\n",
        "sns.regplot(x='A', y='B', data=df)\n",
        "\n",
        "# show the plot\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#This will create a scatterplot with a regression line, showing the relationship between the two variables.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "TBnICORHxjwH",
        "outputId": "c21306df-1bbe-444f-a055-da41e1721572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q15 : What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "####ans :\n",
        "\n",
        "####Causation :\n",
        "\n",
        "Causation refers to the relationship between two events or variables where one event (the cause) leads to the occurrence of the other event (the effect). In other words, causation implies that one variable directly influences the other variable.\n",
        "\n",
        "####Correlation vs. Causation\n",
        "\n",
        "Correlation and causation are often confused with each other, but they are not the same thing. Correlation refers to the statistical relationship between two variables, whereas causation implies a direct cause-and-effect relationship.\n",
        "\n",
        "####Example: Ice Cream Sales and Shark Attacks\n",
        "\n",
        "Suppose we collect data on ice cream sales and shark attacks in a coastal town. We might find a strong positive correlation between the two variables, meaning that when ice cream sales increase, shark attacks also tend to increase.\n",
        "\n",
        "However, this correlation does not imply causation. It's unlikely that eating ice cream causes shark attacks! Instead, there might be a third variable, such as warm weather, that drives both ice cream sales and shark attacks. During warm weather, people are more likely to buy ice cream and engage in water activities, which increases the likelihood of shark encounters.\n",
        "\n",
        "####In this example:\n",
        "\n",
        "- Correlation: Ice cream sales and shark attacks are positively correlated.\n",
        "- Causation: There is no direct causal relationship between eating ice cream and shark attacks.\n",
        "\n",
        "####Key Differences\n",
        "\n",
        "1. Direction: Correlation does not imply direction, whereas causation implies a direct cause-and-effect relationship.\n",
        "2. Mechanism: Correlation does not require a underlying mechanism, whereas causation requires a plausible mechanism explaining how one variable affects the other.\n",
        "3. Third variables: Correlation can be influenced by third variables, whereas causation requires controlling for potential confounding variables.\n",
        "\n",
        "In summary, correlation is a statistical relationship between variables, whereas causation implies a direct cause-and-effect relationship. Establishing causation requires careful consideration of underlying mechanisms, controlling for confounding variables, and ruling out alternative explanations."
      ],
      "metadata": {
        "id": "HaCGfvUdx4kD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q16 : What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "\n",
        "####ans :  \n",
        "\n",
        "#### Optimizer :\n",
        "\n",
        "An optimizer is an algorithm used in machine learning and deep learning to minimize or maximize a loss function or objective function. The goal of an optimizer is to adjust the model's parameters to reduce the error between predicted and actual values.\n",
        "\n",
        "####Types of Optimizers :\n",
        "\n",
        "Here are some common types of optimizers, along with examples:\n",
        "\n",
        "1. Gradient Descent (GD):\n",
        "\n",
        "GD is a first-order optimization algorithm that iteratively adjusts the model's parameters in the direction of the negative gradient of the loss function.\n",
        "\n",
        "Example: Suppose we're training a linear regression model to predict house prices. The GD optimizer would adjust the model's weights and bias to minimize the mean squared error between predicted and actual prices.\n",
        "\n",
        "\n",
        "2. Stochastic Gradient Descent (SGD):\n",
        "\n",
        "SGD is a variant of GD that uses a single example from the training dataset to compute the gradient, rather than the entire dataset.\n",
        "\n",
        "Example: Suppose we're training a neural network to classify images. The SGD optimizer would adjust the model's weights and biases based on a single image example, rather than the entire dataset.\n",
        "\n",
        "3. Mini-Batch Gradient Descent (MBGD):\n",
        "\n",
        "MBGD is a variant of GD that uses a small batch of examples from the training dataset to compute the gradient.\n",
        "\n",
        "Example: Suppose we're training a deep learning model to recognize speech patterns. The MBGD optimizer would adjust the model's weights and biases based on a small batch of audio examples, rather than a single example or the entire dataset.\n",
        "\n",
        "4. Momentum:\n",
        "\n",
        " Momentum is an optimization algorithm that adds a fraction of the previous update to the current update, helping to escape local minima.\n",
        "\n",
        "Example: Suppose we're training a neural network to play a game. The momentum optimizer would adjust the model's weights and biases based on the current gradient, as well as a fraction of the previous update.\n",
        "\n",
        "5. Nesterov Accelerated Gradient (NAG):\n",
        "\n",
        "NAG is an optimization algorithm that modifies the momentum update to incorporate a \"lookahead\" term, helping to escape local minima.\n",
        "\n",
        "Example: Suppose we're training a deep learning model to recognize objects in images. The NAG optimizer would adjust the model's weights and biases based on the current gradient, as well as a lookahead term that anticipates the next update.\n",
        "\n",
        "6. Adam:\n",
        "\n",
        "Adam is an optimization algorithm that adapts the learning rate for each parameter based on the magnitude of the gradient.\n",
        "\n",
        "Example: Suppose we're training a neural network to generate text. The Adam optimizer would adjust the model's weights and biases based on the current gradient, as well as an adaptive learning rate that changes for each parameter.\n",
        "\n",
        "7. RMSProp:\n",
        "\n",
        "RMSProp is an optimization algorithm that divides the learning rate by a moving average of the squared gradient, helping to stabilize the update.\n",
        "\n",
        "Example: Suppose we're training a deep learning model to recognize speech patterns. The RMSProp optimizer would adjust the model's weights and biases based on the current gradient, as well as a moving average of the squared gradient.\n",
        "\n",
        "8. Adagrad:\n",
        "\n",
        "Adagrad is an optimization algorithm that adapts the learning rate for each parameter based on the magnitude of the gradient.\n",
        "\n",
        "Example: Suppose we're training a neural network to classify images. The Adagrad optimizer would adjust the model's weights and biases based on the current gradient, as well as an adaptive learning rate that changes for each parameter.\n",
        "\n",
        "Each optimizer has its strengths and weaknesses, and the choice of optimizer depends on the specific problem, dataset, and model architecture."
      ],
      "metadata": {
        "id": "eFtMvC0pzNEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q17 : What is sklearn.linear_model ?\n",
        "\n",
        "\n",
        "####ans :\n",
        "\n",
        "sklearn.linear_model is a module in the scikit-learn library that provides implementations of various linear models for regression and classification tasks.\n",
        "\n",
        "####The linear_model module includes the following classes and functions:\n",
        "\n",
        "1. Linear Regression: LinearRegression class for ordinary least squares linear regression.\n",
        "2. Ridge Regression: Ridge class for ridge regression, a type of linear regression with L2 regularization.\n",
        "3. Lasso Regression: Lasso class for lasso regression, a type of linear regression with L1 regularization.\n",
        "4. Elastic Net Regression: ElasticNet class for elastic net regression, a type of linear regression with both L1 and L2 regularization.\n",
        "5. Logistic Regression: LogisticRegression class for logistic regression, a type of linear model for binary classification.\n",
        "6. Perceptron: Perceptron class for perceptron, a type of linear model for binary classification.\n",
        "7. SGDClassifier and SGDRegressor: Classes for stochastic gradient descent classification and regression, respectively.\n",
        "\n",
        "These classes provide various methods for fitting models, making predictions, and evaluating model performance. They also offer various parameters for tuning model behavior, such as regularization strength, learning rate, and more.\n",
        "\n",
        "####Some common methods available in these classes include:\n",
        "\n",
        "- fit(): Fit the model to the training data.\n",
        "- predict(): Make predictions on new, unseen data.\n",
        "- score(): Evaluate the model's performance on a given dataset.\n",
        "- coef_ and intercept_: Access the model's coefficients and intercept, respectively.\n",
        "\n",
        "Overall, the sklearn.linear_model module provides a comprehensive set of tools for building and using linear models in Python."
      ],
      "metadata": {
        "id": "iq4fi6jn0uev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q18 : What does model.fit() do? What arguments must be given?\n",
        "\n",
        "\n",
        "####ans :\n",
        "\n",
        "Model.fit() is a method in Keras (and other deep learning frameworks) that trains a neural network model on a given dataset.\n",
        "\n",
        "####When we call model.fit(), the following steps occur:\n",
        "\n",
        "1. Compilation: If the model hasn't been compiled yet, fit() will compile it with the default optimizer, loss function, and metrics.\n",
        "2. Data preparation: The input data is split into batches, and the model is prepared for training.\n",
        "3. Training loop: The model is trained on each batch of data, and the weights are updated after each batch using backpropagation.\n",
        "4. Evaluation: After each epoch (a complete pass through the training data), the model is evaluated on the validation data (if provided).\n",
        "5. Checkpointing: If checkpointing is enabled, the model's weights are saved at regular intervals.\n",
        "\n",
        "\n",
        "####The fit() method requires the following arguments:\n",
        "\n",
        "1. *x*: The input data, which can be a NumPy array, a Pandas DataFrame, or a generator.\n",
        "2. *y*: The target data, which can be a NumPy array, a Pandas DataFrame, or a generator.\n",
        "\n",
        "####Optional arguments include:\n",
        "\n",
        "1. *batch_size*: The number of samples in each batch. Default is 32.\n",
        "2. *epochs*: The number of epochs to train the model. Default is 1.\n",
        "3. *validation_data*: A tuple containing the validation input data and target data.\n",
        "4. *validation_steps*: The number of validation steps to perform.\n",
        "5. *verbose*: The verbosity level, which can be 0 (silent), 1 (progress bar), or 2 (one line per epoch). Default is 1.\n",
        "6. *callbacks*: A list of callback functions to be called at specific points during training.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BsUAUWug2En0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q19 : What does model.predict() do? What arguments must be given?\n",
        "\n",
        "\n",
        "####ans :   \n",
        "\n",
        "\n",
        "model.predict() is a method in Keras that generates output predictions for a given input data.\n",
        "\n",
        "####What does model.predict() do?\n",
        "\n",
        "When we call model.predict(), the following steps occur:\n",
        "\n",
        "1. Input processing: The input data is processed and prepared for prediction.\n",
        "2. Forward pass: The input data is passed through the model's layers, and the output is computed.\n",
        "3. Output generation: The model generates output predictions based on the input data.\n",
        "\n",
        "####arguments :\n",
        "\n",
        "The predict() method requires the following argument:\n",
        "\n",
        "1. *x*: The input data, which can be a NumPy array, a Pandas DataFrame, or a generator.\n",
        "\n",
        "Optional arguments include:\n",
        "\n",
        "1. *batch_size*: The number of samples in each batch. Default is 32.\n",
        "2. *verbose*: The verbosity level, which can be 0 (silent) or 1 (progress bar). Default is 1.\n"
      ],
      "metadata": {
        "id": "uY_0AYRqBlzZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q20 :  What are continuous and categorical variables?\n",
        "\n",
        "\n",
        "####ans :\n",
        "\n",
        " In statistics and machine learning, variables can be classified into two main categories: continuous and categorical.\n",
        "\n",
        "####Continuous Variables :\n",
        "\n",
        "Continuous variables are numerical variables that can take any value within a certain range or interval. They can be measured to any level of precision and can have an infinite number of possible values.\n",
        "\n",
        "Examples of continuous variables:\n",
        "\n",
        "- Height (e.g., 175.2 cm)\n",
        "- Weight (e.g., 65.5 kg)\n",
        "- Temperature (e.g., 23.7°C)\n",
        "- Time (e.g., 12.5 hours)\n",
        "\n",
        "####Categorical Variables :\n",
        "\n",
        "Categorical variables, also known as discrete variables, are variables that can take only a limited number of distinct values. These values are often represented as labels or categories.\n",
        "\n",
        "Examples of categorical variables:\n",
        "\n",
        "- Color (e.g., red, blue, green)\n",
        "- Gender (e.g., male, female)\n",
        "- Nationality (e.g., American, Canadian, Indian)\n",
        "- Product category (e.g., electronics, clothing, home goods)\n",
        "\n",
        "####Categorical variables can be further divided into two subtypes:\n",
        "\n",
        "- Nominal variables: These variables have no inherent order or hierarchy (e.g., color, nationality).\n",
        "- Ordinal variables: These variables have a natural order or hierarchy (e.g., education level: high school, bachelor's, master's).\n",
        "\n",
        "Understanding the type of variable we're working with is important because it determines the types of statistical analyses and machine learning algorithms that can be applied."
      ],
      "metadata": {
        "id": "7xXCunC77fus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q21 : What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "####ans :  \n",
        "\n",
        "Feature scaling, also known as normalization or standardization, is a technique used in machine learning to transform numeric features into a common range, usually between 0 and 1, to prevent differences in scales from affecting model performance.\n",
        "\n",
        "####necessity of feature scaling :  \n",
        "\n",
        "Machine learning algorithms often rely on distance or gradient calculations, which can be influenced by the scale of the features. Features with large ranges can dominate the model, while features with small ranges may have little impact.\n",
        "\n",
        "####Benefits of feature scaling:\n",
        "\n",
        "1. Prevents feature dominance: Scaling ensures that all features contribute equally to the model.\n",
        "2. Improves model convergence: Scaling can speed up convergence and reduce the risk of getting stuck in local minima.\n",
        "3. Enhances interpretability: Scaled features make it easier to understand the relationships between variables.\n",
        "4. Supports distance-based algorithms: Scaling is essential for algorithms like k-NN, k-means, and SVM.\n"
      ],
      "metadata": {
        "id": "RDRgkdz18YW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q22 : How do we perform scaling in Python?\n",
        "\n",
        "\n",
        "####ans :\n",
        "\n",
        " In Python, we can perform scaling using the StandardScaler and MinMaxScaler classes from the sklearn.preprocessing module.\n"
      ],
      "metadata": {
        "id": "A2iMBi9s9U90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Standardization (Z-scoring) :\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample dataset\n",
        "data = np.array([[1., -1., 2.],\n",
        "                  [2., 0., 0.],\n",
        "                  [0., 1., -1.]])\n",
        "\n",
        "# Create a StandardScaler object\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the data and transform it\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrlK0vlu9o9k",
        "outputId": "472e3707-1750-45d1-8bf4-bc24c7ded81b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.         -1.22474487  1.33630621]\n",
            " [ 1.22474487  0.         -0.26726124]\n",
            " [-1.22474487  1.22474487 -1.06904497]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalization (Min-Max scaling) :\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample dataset\n",
        "data = np.array([[1., -1., 2.],\n",
        "                  [2., 0., 0.],\n",
        "                  [0., 1., -1.]])\n",
        "\n",
        "# Create a MinMaxScaler object\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler to the data and transform it\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StR4BHof94cR",
        "outputId": "fc9d25ac-e588-44ce-afde-cbc4a85de87e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5        0.         1.        ]\n",
            " [1.         0.5        0.33333333]\n",
            " [0.         1.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q23 :  What is sklearn.preprocessing?\n",
        "\n",
        "\n",
        "####ans :\n",
        "\n",
        "sklearn.preprocessing is a module in the scikit-learn library that provides various techniques for preprocessing and transforming data. The module includes functions and classes for scaling, normalization, encoding, and other data transformation tasks.\n",
        "\n",
        "####The main goals of preprocessing are:\n",
        "\n",
        "1. Data normalization: Scaling numeric data to a common range to prevent features with large ranges from dominating the model.\n",
        "2. Data transformation: Converting data into a suitable format for modeling, such as encoding categorical variables or handling missing values.\n",
        "3. Feature extraction: Extracting relevant features from the data to improve model performance.\n",
        "\n",
        "####Some of the key classes and functions in sklearn.preprocessing include:\n",
        "\n",
        "1. Scaling:\n",
        "    - StandardScaler: Standardizes features by removing the mean and scaling to unit variance.\n",
        "    - MinMaxScaler: Scales features to a common range, usually between 0 and 1.\n",
        "    - RobustScaler: Scales features using statistics that are robust to outliers.\n",
        "2. Encoding:\n",
        "    - OneHotEncoder: Encodes categorical variables as binary vectors.\n",
        "    - LabelEncoder: Encodes categorical variables as integers.\n",
        "3. Normalization:\n",
        "    - Normalizer: Normalizes samples to have unit norm.\n",
        "4. Feature extraction:\n",
        "    - PCA: Performs principal component analysis to reduce dimensionality.\n",
        "    - KernelPCA: Performs kernel principal component analysis to reduce dimensionality.\n",
        "\n",
        "By using the sklearn.preprocessing module, we can easily preprocess and transform our data to prepare it for modeling and analysis."
      ],
      "metadata": {
        "id": "AnAShknr-QLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q24 : How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "\n",
        "####ans :\n",
        "\n",
        "In Python, we can split data for model fitting using the train_test_split function from the sklearn.model_selection module.\n"
      ],
      "metadata": {
        "id": "8R4Pp-uP_2Df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Here's a basic example:\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample dataset\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 5)\n",
        "y = np.random.randint(0, 2, 100)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing data shape:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMoIhvcPAory",
        "outputId": "1d1413a7-7dc4-4cd9-fd17-f6d0683ff802"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (80, 5) (80,)\n",
            "Testing data shape: (20, 5) (20,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####In this example:\n",
        "\n",
        "- X is the feature matrix (100 samples, 5 features).\n",
        "- y is the target vector (100 samples).\n",
        "- test_size=0.2 means that 20% of the data will be used for testing, and the remaining 80% will be used for training.\n",
        "- random_state=42 ensures that the split is reproducible.\n",
        "\n",
        "The train_test_split function returns four arrays:\n",
        "\n",
        "- X_train: The training feature matrix.\n",
        "- X_test: The testing feature matrix.\n",
        "- y_train: The training target vector.\n",
        "- y_test: The testing target vector.\n",
        "\n",
        "we can adjust the test_size parameter to change the proportion of data used for testing. For example, test_size=0.3 would use 30% of the data for testing.\n",
        "\n",
        "Additionally, we can use the stratify parameter to ensure that the split preserves the class balance. This is particularly useful for imbalanced datasets."
      ],
      "metadata": {
        "id": "QWZSVgnoBH3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "bCFQaJkjBXfj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q25 : Explain data encoding?\n",
        "\n",
        "####ans :   \n",
        "\n",
        "Data encoding is the process of converting data into a format that can be understood and processed by machines, such as computers. The goal of data encoding is to transform data into a numerical representation that can be used for analysis, modeling, and prediction.\n",
        "\n",
        "####Types of Data Encoding:\n",
        "\n",
        "1. Label Encoding: This involves assigning a unique integer value to each category in a categorical variable. For example, in a variable \"Color\" with categories \"Red\", \"Blue\", and \"Green\", label encoding would assign values 0, 1, and 2 to these categories, respectively.\n",
        "\n",
        "2. One-Hot Encoding (OHE): This involves creating new binary variables for each category in a categorical variable. For example, in a variable \"Color\" with categories \"Red\", \"Blue\", and \"Green\", OHE would create three new variables \"Color_Red\", \"Color_Blue\", and \"Color_Green\", each with values 0 or 1.\n",
        "\n",
        "3. Binary Encoding: This involves representing categorical data as binary numbers. For example, in a variable \"Color\" with categories \"Red\", \"Blue\", and \"Green\", binary encoding would represent these categories as 00, 01, and 10, respectively.\n",
        "\n",
        "4. Ordinal Encoding: This involves assigning integer values to ordinal data, which has a natural order or ranking. For example, in a variable \"Size\" with categories \"Small\", \"Medium\", and \"Large\", ordinal encoding would assign values 0, 1, and 2 to these categories, respectively.\n",
        "\n",
        "####Importance of data encoding :\n",
        "\n",
        "1. Machine Learning Algorithms: Many machine learning algorithms require numerical input data. Data encoding enables categorical data to be used with these algorithms.\n",
        "2. Data Analysis: Data encoding facilitates data analysis by enabling categorical data to be treated as numerical data.\n",
        "3. Data Visualization: Data encoding enables categorical data to be visualized using numerical visualization tools.\n"
      ],
      "metadata": {
        "id": "yU9o4FMiB49D"
      }
    }
  ]
}